"""
Alex Thompson - Principal Software Engineer Agent
Generates and implements fixes autonomously
"""
import os
import shutil
import re
import requests
from typing import Dict, List
from datetime import datetime


class FixEngineerAgent:
    """
    Alex Thompson - Principal Software Engineer
    Credentials: 15+ years senior engineering at Amazon/Netflix
    Role: Generate and implement code fixes
    """

    def __init__(self):
        self.name = "Alex Thompson"
        self.role = "Fix Engineer"

    def generate_fix(self, root_cause: Dict) -> Dict:
        """Generate fix for identified root cause"""
        print(f"\n{'='*70}")
        print(f"üîß [{self.role}] {self.name}")
        print(f"   Generating fix for: {root_cause['issue_type']}")
        print(f"{'='*70}\n")

        issue_type = root_cause.get("issue_type")

        # Original fixes
        if issue_type == "database_column_length":
            fix = self._generate_column_length_fix(root_cause)
        elif issue_type == "model_deprecation":
            fix = self._generate_model_upgrade_fix(root_cause)
        elif issue_type == "rate_limiting":
            fix = self._generate_rate_limit_fix(root_cause)
        elif issue_type == "database_errors":
            fix = self._generate_database_fix(root_cause)
        elif issue_type == "connection_errors":
            fix = self._generate_connection_fix(root_cause)

        # ========== EXPANDED FIX GENERATORS ==========

        # Database constraint fixes
        elif issue_type == "database_null_violation":
            fix = self._generate_null_violation_fix(root_cause)
        elif issue_type == "database_unique_violation":
            fix = self._generate_unique_violation_fix(root_cause)

        # Python code error fixes
        elif issue_type == "attribute_errors":
            fix = self._generate_attribute_error_fix(root_cause)
        elif issue_type == "key_errors":
            fix = self._generate_key_error_fix(root_cause)
        elif issue_type == "import_errors":
            fix = self._generate_import_error_fix(root_cause)

        # Frontend/CORS fixes
        elif issue_type == "cors_errors":
            fix = self._generate_cors_fix(root_cause)

        # Validation fixes
        elif issue_type == "validation_errors":
            fix = self._generate_validation_fix(root_cause)

        # File system fixes
        elif issue_type == "file_not_found":
            fix = self._generate_file_not_found_fix(root_cause)

        # Performance fixes
        elif issue_type == "slow_queries":
            fix = self._generate_slow_query_fix(root_cause)

        # Data quality fixes
        elif issue_type == "missing_required_fields":
            fix = self._generate_missing_fields_fix(root_cause)
        elif issue_type == "data_corruption":
            fix = self._generate_data_corruption_fix(root_cause)

        else:
            fix = self._generate_generic_fix(root_cause)

        fix["timestamp"] = datetime.utcnow().isoformat()
        fix["agent"] = self.name

        self._print_fix(fix)

        return fix

    def _generate_column_length_fix(self, root_cause: Dict) -> Dict:
        """Generate fix for database column length issues"""
        print(f"   üîç Detecting column length issue...")

        # Step 1: Parse PostgreSQL logs to find which column is too short
        column_info = self._detect_short_column()

        if not column_info:
            print(f"   ‚ùå Could not detect column information")
            return self._generate_generic_fix(root_cause)

        print(f"   üìå Column found: {column_info['table']}.{column_info['column']}")
        print(f"   üìè Current length: {column_info['current_length']}")
        print(f"   üìè Required length: {column_info['required_length']}")

        # Step 2: Generate fix
        new_length = max(column_info['required_length'] + 50, 500)  # Add buffer, max 500

        return {
            "issue_type": "database_column_length",
            "fix_type": "alter_table_column",
            "confidence": 98,
            "table": column_info['table'],
            "column": column_info['column'],
            "current_length": column_info['current_length'],
            "new_length": new_length,
            "actions": [
                {
                    "action": "alter_column_length",
                    "table": column_info['table'],
                    "column": column_info['column'],
                    "old_length": column_info['current_length'],
                    "new_length": new_length,
                    "change": f"ALTER TABLE {column_info['table']} ALTER COLUMN {column_info['column']} TYPE VARCHAR({new_length})"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,  # Auto-apply with 98% confidence
            "estimated_downtime_seconds": 5
        }

    def _detect_short_column(self) -> dict:
        """Detect which column is too short from PostgreSQL logs"""
        try:
            import subprocess
            result = subprocess.run(
                ["docker", "logs", "--tail", "100", "product-trend-db"],
                capture_output=True,
                text=True,
                timeout=10
            )

            logs = result.stdout + result.stderr

            # Look for "value too long for type character varying(50)"
            import re
            pattern = r'value too long for type character varying\((\d+)\).*UPDATE (\w+) SET.*?(\w+)='
            matches = re.findall(pattern, logs, re.DOTALL)

            if matches:
                current_length = int(matches[-1][0])  # Most recent error
                table = matches[-1][1]
                column = matches[-1][2]

                # Also find the actual length needed
                value_pattern = rf"{column}='([^']*?)'"
                value_matches = re.findall(value_pattern, logs)
                required_length = max(len(v) for v in value_matches) if value_matches else current_length * 2

                return {
                    "table": table,
                    "column": column,
                    "current_length": current_length,
                    "required_length": required_length
                }

            return None

        except Exception as e:
            print(f"   ‚ö†Ô∏è  Error detecting column: {str(e)}")
            return None

    def _generate_model_upgrade_fix(self, root_cause: Dict) -> Dict:
        """Generate fix for model deprecation - research and upgrade"""
        print(f"   üîç Detecting deprecated model...")

        # Step 1: Detect which model is deprecated
        deprecated_model = self._detect_deprecated_model()

        if not deprecated_model:
            print(f"   ‚ùå Could not detect deprecated model")
            return self._generate_generic_fix(root_cause)

        print(f"   üìå Deprecated model found: {deprecated_model}")

        # Step 2: Research replacement model
        print(f"   üåê Researching replacement model...")
        replacement_model = self._research_replacement_model(deprecated_model)

        if not replacement_model:
            print(f"   ‚ùå Could not find replacement model")
            return {
                "issue_type": "model_deprecation",
                "fix_type": "model_upgrade_manual",
                "confidence": 60,
                "deprecated_model": deprecated_model,
                "actions": [{
                    "action": "manual_model_research",
                    "message": f"Model {deprecated_model} is deprecated. Manual research required."
                }],
                "risk_level": "high",
                "rollback_available": True,
                "auto_apply": False,
                "estimated_downtime_seconds": 0
            }

        print(f"   ‚úÖ Replacement found: {replacement_model}")

        # Step 3: Generate fix actions
        return {
            "issue_type": "model_deprecation",
            "fix_type": "model_upgrade_auto",
            "confidence": 92,
            "deprecated_model": deprecated_model,
            "replacement_model": replacement_model,
            "actions": [
                {
                    "action": "update_model_id",
                    "file": "services/ai_analysis/agentic_system.py",
                    "change": f"Upgrade from {deprecated_model} to {replacement_model}",
                    "old_value": deprecated_model,
                    "new_value": replacement_model
                },
                {
                    "action": "update_docs",
                    "files": ["AGENTIC_AI_SETUP.md", "CURRENT_STATUS.md"],
                    "change": f"Update documentation references from {deprecated_model} to {replacement_model}"
                },
                {
                    "action": "test_model",
                    "model": replacement_model,
                    "test_type": "api_call"
                }
            ],
            "risk_level": "medium",
            "rollback_available": True,
            "auto_apply": True,  # Auto-apply with 92% confidence
            "estimated_downtime_seconds": 30
        }

    def _detect_deprecated_model(self) -> str:
        """Detect which model is deprecated from error logs"""
        try:
            # Read recent celery logs
            import subprocess
            result = subprocess.run(
                ["docker", "logs", "--tail", "200", "product-trend-celery"],
                capture_output=True,
                text=True,
                timeout=10
            )

            logs = result.stdout + result.stderr

            # Look for model deprecation patterns
            patterns = [
                r'model.*?`([^`]+)`.*?decommissioned',
                r'model.*?([a-z0-9\-/]+).*?deprecated',
                r'qwen[^"\s]*',
                r'llama[^"\s]*',
                r'groq.*?model.*?([a-z0-9\-/]+)'
            ]

            for pattern in patterns:
                matches = re.findall(pattern, logs, re.IGNORECASE)
                if matches:
                    # Return most common match
                    from collections import Counter
                    most_common = Counter(matches).most_common(1)
                    if most_common:
                        return most_common[0][0].strip('` "\'')

            return None

        except Exception as e:
            print(f"   ‚ö†Ô∏è  Error detecting model: {str(e)}")
            return None

    def _research_replacement_model(self, deprecated_model: str) -> str:
        """Research replacement model using web search simulation"""
        # Map of known deprecations (we can expand this over time)
        known_replacements = {
            "qwen-qwq-32b": "qwen/qwen3-32b",
            "qwq-32b-preview": "qwen/qwen3-32b",
            "llama-3.1-70b": "llama-3.3-70b-versatile",
            "mixtral-8x7b": "llama-3.1-8b-instant"
        }

        # Check known replacements first
        if deprecated_model in known_replacements:
            return known_replacements[deprecated_model]

        # Try to infer replacement from model name
        if "qwen" in deprecated_model.lower():
            return "qwen/qwen3-32b"  # Latest Qwen model on Groq
        elif "llama" in deprecated_model.lower() and "70b" in deprecated_model:
            return "llama-3.3-70b-versatile"
        elif "llama" in deprecated_model.lower():
            return "llama-3.1-8b-instant"

        return None

    def _generate_rate_limit_fix(self, root_cause: Dict) -> Dict:
        """Generate fix for rate limiting"""
        # Check current delay configuration
        current_delay = self._get_current_delay()

        if current_delay < 1.0:
            # Increase delay
            new_delay = min(current_delay + 0.3, 2.0)

            return {
                "issue_type": "rate_limiting",
                "fix_type": "increase_delay",
                "confidence": 92,
                "actions": [
                    {
                        "action": "increase_api_delay",
                        "file": "services/ai_analysis/agentic_system.py",
                        "change": f"Increase asyncio.sleep from {current_delay}s to {new_delay}s",
                        "current_value": current_delay,
                        "new_value": new_delay
                    }
                ],
                "risk_level": "low",
                "rollback_available": True,
                "auto_apply": True,  # Safe to auto-apply
                "estimated_downtime_seconds": 0
            }
        else:
            # Delay already high, reduce batch size
            return {
                "issue_type": "rate_limiting",
                "fix_type": "reduce_batch_size",
                "confidence": 88,
                "actions": [
                    {
                        "action": "reduce_batch_size",
                        "file": "tasks/analysis_tasks.py",
                        "change": "Reduce batch size from 5 to 3 products",
                        "current_value": 5,
                        "new_value": 3
                    }
                ],
                "risk_level": "low",
                "rollback_available": True,
                "auto_apply": True,
                "estimated_downtime_seconds": 0
            }

    def _generate_database_fix(self, root_cause: Dict) -> Dict:
        """Generate fix for database errors"""
        return {
            "issue_type": "database_errors",
            "fix_type": "increase_timeout_and_retry",
            "confidence": 90,
            "actions": [
                {
                    "action": "increase_connection_timeout",
                    "file": "models/database.py",
                    "change": "Increase connection timeout from 5s to 30s",
                    "current_value": 5,
                    "new_value": 30
                },
                {
                    "action": "add_retry_logic",
                    "file": "models/database.py",
                    "change": "Add retry decorator with 3 attempts",
                    "implementation": "Use tenacity library for retries"
                }
            ],
            "risk_level": "medium",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 10
        }

    def _generate_connection_fix(self, root_cause: Dict) -> Dict:
        """Generate fix for connection errors"""
        return {
            "issue_type": "connection_errors",
            "fix_type": "add_exponential_backoff",
            "confidence": 85,
            "actions": [
                {
                    "action": "add_retry_with_backoff",
                    "file": "services/ai_analysis/agentic_system.py",
                    "change": "Add exponential backoff to API calls",
                    "implementation": "Retry with 1s, 2s, 4s delays"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 0
        }

    def _generate_generic_fix(self, root_cause: Dict) -> Dict:
        """Generate generic fix"""
        return {
            "issue_type": root_cause.get("issue_type"),
            "fix_type": "manual_review_required",
            "confidence": 60,
            "actions": [
                {
                    "action": "log_for_review",
                    "message": "Issue requires manual investigation"
                }
            ],
            "risk_level": "unknown",
            "rollback_available": False,
            "auto_apply": False,  # Don't auto-apply low confidence fixes
            "estimated_downtime_seconds": 0
        }

    # ========== EXPANDED FIX GENERATORS ==========

    def _generate_null_violation_fix(self, root_cause: Dict) -> Dict:
        """Fix NULL constraint violations by adding defaults"""
        return {
            "issue_type": "database_null_violation",
            "fix_type": "add_column_default",
            "confidence": 90,
            "actions": [
                {
                    "action": "detect_null_column",
                    "change": "Parse error logs to find column with NULL violation"
                },
                {
                    "action": "add_default_value",
                    "change": "ALTER TABLE to add DEFAULT value or update code to provide defaults"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 5
        }

    def _generate_unique_violation_fix(self, root_cause: Dict) -> Dict:
        """Fix duplicate key violations"""
        return {
            "issue_type": "database_unique_violation",
            "fix_type": "add_upsert_logic",
            "confidence": 85,
            "actions": [
                {
                    "action": "detect_duplicate_column",
                    "change": "Identify which column has unique constraint"
                },
                {
                    "action": "implement_upsert",
                    "change": "Add INSERT ... ON CONFLICT DO UPDATE logic"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 0
        }

    def _generate_attribute_error_fix(self, root_cause: Dict) -> Dict:
        """Fix AttributeError by adding hasattr checks"""
        return {
            "issue_type": "attribute_errors",
            "fix_type": "add_attribute_checks",
            "confidence": 80,
            "actions": [
                {
                    "action": "parse_traceback",
                    "change": "Find line and attribute causing error"
                },
                {
                    "action": "add_hasattr_check",
                    "change": "Wrap attribute access with hasattr() or getattr(obj, attr, default)"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 0
        }

    def _generate_key_error_fix(self, root_cause: Dict) -> Dict:
        """Fix KeyError by using .get() method"""
        return {
            "issue_type": "key_errors",
            "fix_type": "replace_with_dict_get",
            "confidence": 80,
            "actions": [
                {
                    "action": "parse_traceback",
                    "change": "Find dict and key causing error"
                },
                {
                    "action": "replace_dict_access",
                    "change": "Replace dict[key] with dict.get(key, default_value)"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 0
        }

    def _generate_import_error_fix(self, root_cause: Dict) -> Dict:
        """Fix ImportError by installing missing package"""
        return {
            "issue_type": "import_errors",
            "fix_type": "install_package",
            "confidence": 95,
            "actions": [
                {
                    "action": "detect_missing_module",
                    "change": "Extract module name from ImportError"
                },
                {
                    "action": "install_pip_package",
                    "change": "Run pip install <module> in container"
                },
                {
                    "action": "update_requirements",
                    "change": "Add module to requirements.txt"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 30
        }

    def _generate_cors_fix(self, root_cause: Dict) -> Dict:
        """Fix CORS errors by updating middleware"""
        return {
            "issue_type": "cors_errors",
            "fix_type": "update_cors_middleware",
            "confidence": 90,
            "actions": [
                {
                    "action": "detect_origin",
                    "change": "Extract blocked origin from error logs"
                },
                {
                    "action": "update_cors_config",
                    "file": "api/main.py",
                    "change": "Add origin to CORS allowed origins list"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 10
        }

    def _generate_validation_fix(self, root_cause: Dict) -> Dict:
        """Fix validation errors"""
        return {
            "issue_type": "validation_errors",
            "fix_type": "update_validation_schema",
            "confidence": 75,
            "actions": [
                {
                    "action": "analyze_validation_failures",
                    "change": "Parse error logs to find validation pattern"
                },
                {
                    "action": "update_schema",
                    "change": "Update Pydantic models or validation rules"
                }
            ],
            "risk_level": "medium",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 0
        }

    def _generate_file_not_found_fix(self, root_cause: Dict) -> Dict:
        """Fix FileNotFoundError"""
        return {
            "issue_type": "file_not_found",
            "fix_type": "create_missing_file",
            "confidence": 85,
            "actions": [
                {
                    "action": "detect_missing_path",
                    "change": "Extract file path from error"
                },
                {
                    "action": "create_file_or_directory",
                    "change": "Create missing file/directory with appropriate defaults"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 0
        }

    def _generate_slow_query_fix(self, root_cause: Dict) -> Dict:
        """Fix slow database queries"""
        return {
            "issue_type": "slow_queries",
            "fix_type": "add_database_index",
            "confidence": 75,
            "actions": [
                {
                    "action": "identify_slow_query",
                    "change": "Parse logs to find slow query SQL"
                },
                {
                    "action": "analyze_query_plan",
                    "change": "Run EXPLAIN ANALYZE to find bottlenecks"
                },
                {
                    "action": "create_index",
                    "change": "CREATE INDEX on frequently filtered columns"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 10
        }

    def _generate_missing_fields_fix(self, root_cause: Dict) -> Dict:
        """Fix missing required fields"""
        return {
            "issue_type": "missing_required_fields",
            "fix_type": "add_field_defaults",
            "confidence": 80,
            "actions": [
                {
                    "action": "detect_missing_fields",
                    "change": "Parse error to find which fields are missing"
                },
                {
                    "action": "add_defaults",
                    "change": "Update code to provide default values for required fields"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 0
        }

    def _generate_data_corruption_fix(self, root_cause: Dict) -> Dict:
        """Fix data corruption (e.g., string 'null' instead of NULL)"""
        return {
            "issue_type": "data_corruption",
            "fix_type": "clean_corrupt_json_fields",
            "confidence": 85,
            "actions": [
                {
                    "action": "scan_database_for_null_strings",
                    "change": "Find all records with string 'null' in JSON fields",
                    "fields": ["ai_keywords", "ai_description", "ai_category"]
                },
                {
                    "action": "replace_null_strings",
                    "change": "UPDATE products SET ai_keywords = NULL WHERE ai_keywords = 'null'"
                },
                {
                    "action": "add_frontend_validation",
                    "change": "Update frontend to safely parse JSON fields with type checking"
                }
            ],
            "risk_level": "low",
            "rollback_available": True,
            "auto_apply": True,
            "estimated_downtime_seconds": 5
        }

    def _get_current_delay(self) -> float:
        """Get current asyncio.sleep delay from code"""
        try:
            file_path = "/app/services/ai_analysis/agentic_system.py"
            if os.path.exists(file_path):
                with open(file_path, "r") as f:
                    content = f.read()
                    # Look for asyncio.sleep(X.X)
                    import re
                    match = re.search(r'asyncio\.sleep\((\d+\.?\d*)\)', content)
                    if match:
                        return float(match.group(1))
            return 0.8  # Default
        except:
            return 0.8

    def apply_fix(self, fix: Dict) -> Dict:
        """Apply the fix (with backup)"""
        if not fix.get("auto_apply", False):
            return {
                "status": "skipped",
                "reason": "Fix requires manual approval or low confidence"
            }

        print(f"\nüîß Applying fix: {fix['fix_type']}")

        try:
            # Create backup first
            backups = self._create_backup(fix)

            # Apply each action
            results = []
            for action in fix["actions"]:
                result = self._apply_action(action)
                results.append(result)

            # Restart affected services if needed
            if any(r.get("restart_required") for r in results):
                self._restart_services(fix)

            return {
                "status": "success",
                "backups": backups,
                "results": results,
                "timestamp": datetime.utcnow().isoformat()
            }

        except Exception as e:
            print(f"‚ùå Fix application failed: {str(e)}")
            return {
                "status": "failed",
                "error": str(e)
            }

    def _create_backup(self, fix: Dict) -> List[str]:
        """Create backup of files before modification"""
        backups = []
        backup_dir = f"/app/backups/{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"

        try:
            os.makedirs(backup_dir, exist_ok=True)

            for action in fix["actions"]:
                if "file" in action:
                    source_file = f"/app/{action['file']}"
                    if os.path.exists(source_file):
                        backup_file = f"{backup_dir}/{os.path.basename(source_file)}"
                        shutil.copy2(source_file, backup_file)
                        backups.append(backup_file)
                        print(f"   ‚úì Backed up: {action['file']}")

        except Exception as e:
            print(f"   ‚ö†Ô∏è  Backup warning: {str(e)}")

        return backups

    def _apply_action(self, action: Dict) -> Dict:
        """Apply a single fix action"""
        action_type = action.get("action")

        if action_type == "alter_column_length":
            return self._apply_alter_column(action)
        elif action_type == "update_model_id":
            return self._apply_model_upgrade(action)
        elif action_type == "update_docs":
            return self._apply_doc_updates(action)
        elif action_type == "test_model":
            return self._apply_model_test(action)
        elif action_type == "increase_api_delay":
            return self._apply_delay_increase(action)
        elif action_type == "reduce_batch_size":
            return self._apply_batch_size_reduction(action)
        elif action_type == "increase_connection_timeout":
            return self._apply_timeout_increase(action)
        else:
            return {"status": "skipped", "reason": f"Action type {action_type} not implemented"}

    def _apply_alter_column(self, action: Dict) -> Dict:
        """Apply ALTER TABLE to increase column length"""
        try:
            table = action['table']
            column = action['column']
            old_length = action['old_length']
            new_length = action['new_length']

            print(f"   üîß Altering database column...")
            print(f"      Table: {table}")
            print(f"      Column: {column}")
            print(f"      {old_length} ‚Üí {new_length} characters")

            # Run ALTER TABLE via docker exec psql
            import subprocess
            alter_sql = f"ALTER TABLE {table} ALTER COLUMN {column} TYPE VARCHAR({new_length});"

            result = subprocess.run([
                "docker", "exec", "product-trend-db",
                "psql", "-U", "postgres", "-d", "product_trends",
                "-c", alter_sql
            ], capture_output=True, text=True, timeout=30)

            if result.returncode == 0:
                print(f"   ‚úì Column altered successfully!")

                return {
                    "status": "success",
                    "action": "alter_column_length",
                    "table": table,
                    "column": column,
                    "old_length": old_length,
                    "new_length": new_length,
                    "restart_required": False  # Database schema changes don't require Celery restart
                }
            else:
                print(f"   ‚ùå ALTER TABLE failed: {result.stderr}")
                return {
                    "status": "error",
                    "reason": result.stderr[:200]
                }

        except Exception as e:
            return {"status": "error", "reason": str(e)}

    def _apply_model_upgrade(self, action: Dict) -> Dict:
        """Upgrade model ID in agentic_system.py"""
        try:
            file_path = f"/app/{action['file']}"
            old_model = action['old_value']
            new_model = action['new_value']

            if not os.path.exists(file_path):
                return {"status": "error", "reason": "File not found"}

            with open(file_path, "r") as f:
                content = f.read()

            # Replace all occurrences of old model with new model
            # Handle both quoted and unquoted versions
            replacements = [
                (f'"{old_model}"', f'"{new_model}"'),
                (f"'{old_model}'", f"'{new_model}'"),
                (old_model, new_model)  # Fallback for any other format
            ]

            new_content = content
            for old, new in replacements:
                new_content = new_content.replace(old, new)

            # Write updated content
            with open(file_path, "w") as f:
                f.write(new_content)

            print(f"   ‚úì Upgraded model: {old_model} ‚Üí {new_model}")

            return {
                "status": "success",
                "action": "update_model_id",
                "old_model": old_model,
                "new_model": new_model,
                "restart_required": True
            }

        except Exception as e:
            return {"status": "error", "reason": str(e)}

    def _apply_doc_updates(self, action: Dict) -> Dict:
        """Update documentation files with new model name"""
        try:
            updated_files = []
            for doc_file in action.get("files", []):
                file_path = f"/app/{doc_file}"
                if os.path.exists(file_path):
                    # Just touch the file to mark it for review
                    # Actual doc updates can be done later
                    print(f"   ‚ÑπÔ∏è  Doc update queued: {doc_file}")
                    updated_files.append(doc_file)

            return {
                "status": "success",
                "action": "update_docs",
                "files_updated": updated_files,
                "restart_required": False
            }

        except Exception as e:
            return {"status": "error", "reason": str(e)}

    def _apply_model_test(self, action: Dict) -> Dict:
        """Test new model with direct API call"""
        try:
            model = action.get("model")
            print(f"   üß™ Testing new model: {model}...")

            # Import required libraries
            groq_api_key = os.getenv("GROQ_API_KEY")
            if not groq_api_key:
                return {"status": "warning", "reason": "GROQ_API_KEY not found"}

            # Test with simple API call
            response = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {groq_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": "Test"}],
                    "temperature": 0.6,
                    "top_p": 0.95,
                    "max_tokens": 50
                },
                timeout=15
            )

            if response.status_code == 200:
                print(f"   ‚úÖ Model test successful!")
                return {
                    "status": "success",
                    "action": "test_model",
                    "model": model,
                    "api_response_code": 200,
                    "restart_required": False
                }
            else:
                print(f"   ‚ùå Model test failed: {response.status_code}")
                return {
                    "status": "failed",
                    "action": "test_model",
                    "model": model,
                    "api_response_code": response.status_code,
                    "error": response.text[:200],
                    "restart_required": False
                }

        except Exception as e:
            return {"status": "error", "reason": str(e)}

    def _apply_delay_increase(self, action: Dict) -> Dict:
        """Increase asyncio.sleep delay"""
        try:
            file_path = f"/app/{action['file']}"
            old_delay = action['current_value']
            new_delay = action['new_value']

            if os.path.exists(file_path):
                with open(file_path, "r") as f:
                    content = f.read()

                # Replace old delay with new delay
                import re
                pattern = f'asyncio\\.sleep\\({old_delay}\\)'
                replacement = f'asyncio.sleep({new_delay})'
                new_content = re.sub(pattern, replacement, content)

                with open(file_path, "w") as f:
                    f.write(new_content)

                print(f"   ‚úì Increased delay: {old_delay}s ‚Üí {new_delay}s")

                return {
                    "status": "success",
                    "action": "increase_api_delay",
                    "restart_required": True
                }
            else:
                return {"status": "error", "reason": "File not found"}

        except Exception as e:
            return {"status": "error", "reason": str(e)}

    def _apply_batch_size_reduction(self, action: Dict) -> Dict:
        """Reduce batch size"""
        try:
            file_path = f"/app/{action['file']}"
            old_size = action['current_value']
            new_size = action['new_value']

            if os.path.exists(file_path):
                with open(file_path, "r") as f:
                    content = f.read()

                # Replace .limit(5) with .limit(3)
                import re
                pattern = f'\\.limit\\({old_size}\\)'
                replacement = f'.limit({new_size})'
                new_content = re.sub(pattern, replacement, content)

                with open(file_path, "w") as f:
                    f.write(new_content)

                print(f"   ‚úì Reduced batch size: {old_size} ‚Üí {new_size}")

                return {
                    "status": "success",
                    "action": "reduce_batch_size",
                    "restart_required": True
                }
            else:
                return {"status": "error", "reason": "File not found"}

        except Exception as e:
            return {"status": "error", "reason": str(e)}

    def _apply_timeout_increase(self, action: Dict) -> Dict:
        """Placeholder for timeout increase"""
        print(f"   ‚ö†Ô∏è  Action not yet implemented: {action['action']}")
        return {"status": "skipped", "reason": "Not implemented"}

    def _restart_services(self, fix: Dict):
        """Restart affected services with delay to allow logging/validation"""
        print(f"\n   üîÑ Scheduling service restart...")
        print(f"   ‚è∞ Restart will occur in 3 minutes (after validation)")

        try:
            # Schedule delayed restart using 'at' command or background process
            # This allows the current task to complete logging and validation first
            import subprocess

            # Run restart in background with 180 second delay (3 minutes)
            # This gives time for:
            # - Logging (instant)
            # - Validation (120 seconds)
            # - Buffer (60 seconds)
            restart_cmd = "sleep 180 && docker restart product-trend-celery product-trend-backend &"
            subprocess.Popen(restart_cmd, shell=True)

            print(f"   ‚úì Delayed restart scheduled")

        except Exception as e:
            print(f"   ‚ö†Ô∏è  Service restart scheduling failed: {str(e)}")

    def _print_fix(self, fix: Dict):
        """Print fix details"""
        print(f"üí° Fix Generated:")
        print(f"   Type: {fix['fix_type']}")
        print(f"   Confidence: {fix['confidence']}%")
        print(f"   Risk Level: {fix['risk_level']}")
        print(f"   Auto-Apply: {'YES' if fix.get('auto_apply') else 'NO'}")
        print(f"   Actions: {len(fix['actions'])}")

        for action in fix['actions']:
            print(f"\n   Action: {action['action']}")
            if 'change' in action:
                print(f"   Change: {action['change']}")

        print(f"\n{'='*70}\n")
